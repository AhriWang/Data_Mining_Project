import pandas as pd
import numpy as np
import re
import nltk
from nltk.tokenize import word_tokenize
from nltk.corpus import stopwords
from gensim.models import Word2Vec
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score
import joblib
import nltk
nltk.download('punkt')

# 1ï¸âƒ£ åŠ è½½ Word2Vec è¯å‘é‡æ¨¡å‹
word2vec_model = Word2Vec.load("/root/datamining/word2vecmodel/amazon_word2vec.model")


# 2ï¸âƒ£  åŠ è½½ Amazon æ•°æ®é›†ï¼ˆæ— è¡¨å¤´ï¼Œæ‰‹åŠ¨åŠ åˆ—åï¼‰
def load_amazon_data(file_path):
    column_names = ["label", "review_title", "review_text"]
    df = pd.read_csv(file_path, header=None, names=column_names)

    # åˆå¹¶æ ‡é¢˜å’Œè¯„è®ºæ–‡æœ¬
    df["combined_text"] = df["review_title"].fillna("") + " " + df["review_text"].fillna("")

    # ç»Ÿä¸€ labelï¼ˆ0: è´Ÿé¢, 1: æ­£é¢ï¼‰
    df["label"] = df["label"].map({1: 0, 2: 1})

    return df["combined_text"].tolist(), df["label"].values


# 3ï¸âƒ£ æ–‡æœ¬é¢„å¤„ç†ï¼ˆå»é™¤ç‰¹æ®Šå­—ç¬¦ã€åˆ†è¯ã€å»åœç”¨è¯ï¼‰
nltk.download("punkt")
nltk.download("stopwords")


def preprocess_text(text_list):
    stop_words = set(stopwords.words("english"))
    processed_texts = []

    for text in text_list:
        if isinstance(text, str):
            text = text.lower()  # è½¬å°å†™
            text = re.sub(r"[^a-zA-Z\s]", "", text)  # å»é™¤ç‰¹æ®Šå­—ç¬¦
            words = word_tokenize(text)  # åˆ†è¯
            words = [w for w in words if w not in stop_words and len(w) > 1]  # å»é™¤åœç”¨è¯
            processed_texts.append(words)

    return processed_texts


# 4ï¸âƒ£ å°†è¯„è®ºè½¬æ¢ä¸ºå›ºå®šå¤§å°çš„å‘é‡
def sentence_vector(words, model):
    vectors = [model.wv[word] for word in words if word in model.wv]
    return np.mean(vectors, axis=0) if vectors else np.zeros(model.vector_size)


# 5ï¸âƒ£ è®­ç»ƒæƒ…æ„Ÿåˆ†ç±»å™¨ï¼ˆéšæœºæ£®æ—ï¼‰
def train_classifier(X, y):
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

    clf = RandomForestClassifier(n_estimators=100, random_state=42)
    clf.fit(X_train, y_train)

    y_pred = clf.predict(X_test)
    print("ğŸ¯ åˆ†ç±»æ¨¡å‹å‡†ç¡®ç‡:", accuracy_score(y_test, y_pred))

    return clf


# 6ï¸âƒ£ ä¸»å‡½æ•°
def main():
    train_file_path = "/root/datamining/train_part_1.csv"

    print("ğŸ”¹ åŠ è½½æ•°æ®...")
    reviews, labels = load_amazon_data(train_file_path)
    print(f"âœ… åŠ è½½ {len(reviews)} æ¡è¯„è®º")

    print("ğŸ”¹ æ–‡æœ¬é¢„å¤„ç†...")
    processed_texts = preprocess_text(reviews)
    print(f"âœ… å¤„ç† {len(processed_texts)} æ¡è¯„è®º")

    print("ğŸ”¹ è®¡ç®—è¯„è®ºå‘é‡...")
    X_vectors = np.array([sentence_vector(words, word2vec_model) for words in processed_texts])

    print("ğŸ”¹ è®­ç»ƒæƒ…æ„Ÿåˆ†ç±»æ¨¡å‹...")
    classifier = train_classifier(X_vectors, labels)
    print("âœ… è®­ç»ƒå®Œæˆï¼")

    # ä¿å­˜åˆ†ç±»æ¨¡å‹
    joblib.dump(classifier, "amazon_sentiment_classifier.pkl")
    print("âœ… åˆ†ç±»å™¨å·²ä¿å­˜")


if __name__ == "__main__":
    main()
